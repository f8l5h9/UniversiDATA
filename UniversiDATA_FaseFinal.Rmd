---
title: "Sistema de Alerta Temprana de Estudiantes Universitarios con Riesgo de Abandono"
subtitle: |
  | Algoritmos de Machine Learning y Datos Abiertos
  |  
  | **Proyecto presentado al concurso "II Datathon UniversiDATA"**
  |
  |  **FASE FINAL 3 FEBRERO 2025**
  |
  |  **No citar este borrador sin permiso del autor**
  |  
  | Fernando A. López Hernández
  | Catedrático de Universidad
  | Universidad Politécnica de Cartagena

abstract: |
  Uno de los principales problemas del sistema educativo español es el alto porcentaje de estudiantes que abandonan la educación superior. Según el informe "Datos y Cifras del Sistema Universitario Español (2022-2023)", uno de cada tres estudiantes universitarios deja sus estudios o cambia de titulación. Implementar un sistema de alerta temprana basado en el análisis de datos masivos puede ser una herramienta eficaz para reducir esta tasa de abandono. Utilizando una base de datos de más de 200.000 estudiantes de de primer curso pertenecientes a cinco universidades españolas de seis cursos académicos se aplican dos algoritmos de aprendizaje automático, Multivariate Adaptive Regression Splines (MARS) y Bosques Aletorios, para asignar a cada estudiante una probabilidad de abandono, permitiendo identificar a aquellos estudiantes con mayor riesgo de abandono. Con base en estas probabilidades, se pueden diseñar estrategias específicas para tratar a los estudiantes según sus características individuales. Esta metodología no solo ayuda a disminuir el abandono, sino que también optimiza los recursos educativos y mejora la experiencia de los estudiantes y de sus familias.

keywords: 
  - Abandono Universitario
  - Machine Learning 
  - UniversiData
  
output: 
  pdf_document:
    number_section: yes
bibliography: UniversiDATA.bib
link-citations: yes
linkcolor: blue
fontsize: 12pt
preamble: >
  \usepackage{siunitx}
  \usepackage{caption}
  \usepackage{tabularx}
  \usepackage[fontsize=12pt]{scrextend}
  \captionsetup[figure]{font=normalsize}
  \captionsetup[table]{font=normalsize}
  \captionsetup{labelfont=bf}
  \documentclass{article}
  \usepackage{booktabs}
  \usepackage{csquotes}
  \usepackage[backend = biber, style = apa]{biblatex}
---

Word count: `r as.integer(sub("(\\d+).+$", "\\1", system(sprintf("wc -w %s", knitr::current_input()), intern = TRUE))) - 20`

<!-- 
Lectura de datos
Código reproducible
-->

```{r paquetes, echo=FALSE, warning = FALSE, message = FALSE}
library(stringr)
library(openxlsx)
library(readxl)
library(dplyr)
library(earth)
library(plotmo)
```

```{r leer datos matricula, echo=FALSE, warning = FALSE, message = FALSE, cache=TRUE}
# UCM
# ================
ucm.1718 <- read_xlsx("Data/ucm-matriculas-2017-18-anonimizado_4.xlsx")
ucm.1718$edad <- 2018-ucm.1718$anio_nacimiento
ucm.1819 <- read_xlsx("Data/ucm-matriculas-2018-19-anonimizado_4.xlsx")
ucm.1819$edad <- 2019-ucm.1819$anio_nacimiento
ucm.1920 <- read_xlsx("Data/ucm-matriculas-2019-20-anonimizado.xlsx")
ucm.1920$edad <- 2020-ucm.1920$anio_nacimiento
ucm.2021 <- read_xlsx("Data/ucm-matriculas-2020-21-anonimizado.xlsx")
ucm.2021$edad <- 2021-ucm.2021$anio_nacimiento
ucm.2122 <- read_xlsx("Data/ucm-matriculas-2021-22-anonimizado.xlsx")
ucm.2122$edad <- 2022-ucm.2122$anio_nacimiento
ucm.2223 <- read_xlsx("Data/ucm-matriculas-2022-23-anonimizado.xlsx")
ucm.2223$edad <- 2023-ucm.2223$anio_nacimiento
ucm <- rbind(ucm.1718,ucm.1819,ucm.1920,ucm.2021,ucm.2122,ucm.2223)
rm(ucm.1718,ucm.1819,ucm.1920,ucm.2021,ucm.2122,ucm.2223)
ucm <- ucm[ucm$des_tipo_estudio=="Grado",]

# UAM
# ================
uam.1718 <- read_xlsx("Data/uam-matriculas-2017-18-anonimizado_2.xlsx")
uam.1718$edad <- 2018-uam.1718$anio_nacimiento
uam.1819 <- read_xlsx("Data/uam-matriculas-2018-19-anonimizado_1.xlsx")
uam.1819$edad <- 2019-uam.1819$anio_nacimiento
uam.1920 <- read_xlsx("Data/uam-matriculas-2019-20-anonimizado.xlsx")
uam.1920$edad <- 2020-uam.1920$anio_nacimiento
uam.2021 <- read_xlsx("Data/uam-matriculas-2020-21-anonimizado.xlsx")
uam.2021$edad <- 2021-uam.2021$anio_nacimiento
uam.2122 <- read_xlsx("Data/uam-matriculas-2021-22-anonimizado.xlsx")
uam.2122$edad <- 2022-uam.2122$anio_nacimiento
uam.2223 <- read_xlsx("Data/uam-matriculas-2022-23-anonimizado.xlsx")
uam.2223$edad <- 2023-uam.2223$anio_nacimiento
uam <- rbind(uam.1718,uam.1819,uam.1920,uam.2021,uam.2122,uam.2223)
rm(uam.1718,uam.1819,uam.1920,uam.2021,uam.2122,uam.2223)
uam <- uam[uam$des_tipo_estudio=="Grado",]

# UVa
# ================
uva.1718 <- read_xlsx("Data/uva-matriculas-2017-18-anonimizado_1.xlsx")
uva.1718$edad <- 2018-uva.1718$anio_nacimiento
uva.1819 <- read_xlsx("Data/uva-matriculas-2018-19-anonimizado_1.xlsx")
uva.1819$edad <- 2019-uva.1819$anio_nacimiento
uva.1920 <- read_xlsx("Data/uva-matriculas-2019-20-anonimizado_1.xlsx")
uva.1920$edad <- 2020-uva.1920$anio_nacimiento
uva.2021 <- read_xlsx("Data/uva-matriculas-2020-21-anonimizado.xlsx")
uva.2021$edad <- 2021-uva.2021$anio_nacimiento
uva.2122 <- read_xlsx("Data/uva-matriculas-2021-22-anonimizado.xlsx")
uva.2122$edad <- 2022-uva.2122$anio_nacimiento
uva.2223 <- read_xlsx("Data/uva-matriculas-2022-23-anonimizado.xlsx")
uva.2223$edad <- 2023-uva.2223$anio_nacimiento
uva <- rbind(uva.1718,uva.1819,uva.1920,uva.2021,uva.2122,uva.2223)
rm(uva.1718,uva.1819,uva.1920,uva.2021,uva.2122,uva.2223)
uva <- uva[uva$des_tipo_estudio=="Grado",]

# UC3M
# ================
uc3m.1718 <- read_xlsx("Data/uc3m-matriculas-2017-18-anonimizado_0.xlsx")
uc3m.1718$edad <- 2018-uc3m.1718$anio_nacimiento
uc3m.1819 <- read_xlsx("Data/uc3m-matriculas-2018-19-anonimizado_0.xlsx")
uc3m.1819$edad <- 2019-uc3m.1819$anio_nacimiento
uc3m.1920 <- read_xlsx("Data/uc3m-matriculas-2019-20-anonimizado_0.xlsx")
uc3m.1920$edad <- 2020-uc3m.1920$anio_nacimiento
uc3m.2021 <- read_xlsx("Data/uc3m-matriculas-2020-21-anonimizado.xlsx")
uc3m.2021$edad <- 2021-uc3m.2021$anio_nacimiento
uc3m.2122 <- read_xlsx("Data/uc3m-matriculas-2021-22-anonimizado.xlsx")
uc3m.2122$edad <- 2022-uc3m.2122$anio_nacimiento
uc3m.2223 <- read_xlsx("Data/uc3m-matriculas-2022-23-anonimizado.xlsx")
uc3m.2223$edad <- 2023-uc3m.2223$anio_nacimiento
uc3m <- rbind(uc3m.1718,uc3m.1819,uc3m.1920,uc3m.2021,uc3m.2122,uc3m.2223)
rm(uc3m.1718,uc3m.1819,uc3m.1920,uc3m.2021,uc3m.2122,uc3m.2223)
uc3m <- uc3m[uc3m$des_tipo_estudio=="Grado",]

# URJC
# ================
urjc.1718 <- read_xlsx("Data/urjc-matriculas-2017-18-anonimizado_2.xlsx")
urjc.1718$edad <- 2018-urjc.1718$anio_nacimiento
urjc.1819 <- read_xlsx("Data/urjc-matriculas-2018-19-anonimizado_1.xlsx")
urjc.1819$edad <- 2019-urjc.1819$anio_nacimiento
urjc.1920 <- read_xlsx("Data/urjc-matriculas-2019-20-anonimizado.xlsx")
urjc.1920$edad <- 2020-urjc.1920$anio_nacimiento
urjc.2021 <- read_xlsx("Data/urjc-matriculas-2020-21-anonimizado.xlsx")
urjc.2021$edad <- 2021-urjc.2021$anio_nacimiento
urjc.2122 <- read_xlsx("Data/urjc-matriculas-2021-22-anonimizado.xlsx")
urjc.2122$edad <- 2022-urjc.2122$anio_nacimiento
urjc.2223 <- read_xlsx("Data/urjc-matriculas-2022-23-anonimizado.xlsx")
urjc.2223$edad <- 2023-urjc.2223$anio_nacimiento
urjc <- rbind(urjc.1718,urjc.1819,urjc.1920,urjc.2021,urjc.2122,urjc.2223)
rm(urjc.1718,urjc.1819,urjc.1920,urjc.2021,urjc.2122,urjc.2223)
urjc <- urjc[urjc$des_tipo_estudio=="Grado",]
```

```{r filtro solo alumnos de primero, echo=FALSE, warning = FALSE, message = FALSE, cache=TRUE}
# Alumnos de primero
# UCM
# UCM ====================
bd <- ucm
bd <- bd[!is.na(bd$des_titulacion),]
bd <- bd[bd$ind_se_titula_curso=="NO",]
bd <- bd[bd$num_total_creditos_mat_curso!=0,]
bd <- bd[bd$num_total_creditos_transf_inicio==0,]
bd <- bd[bd$num_total_creditos_rec_conv_inicio==0,]
bd <- bd[(bd$num_creditos_mat_1_curso==bd$num_total_creditos_mat_inicio),]
bd <- bd[,c(2,4,26,28,42,43,47,51:63,81)]
bd$adscrito <- as.factor(!str_detect(bd$des_centro,"Facultad"))
bd$des_genero <- as.factor(bd$des_genero)
bd$curso_academico <- as.factor(bd$curso_academico)
bd$cod_universidad <- as.factor(bd$cod_universidad)
bd$doble <- as.factor(str_detect(bd$des_titulacion,"DOBLE"))
bd$mm <- bd$des_municipio_residencia=="MADRID"
bd$pm <- bd$des_provincia_residencia=="Madrid"
hh <- bd %>% group_by(cod_titulacion) %>% 
  summarise(n.titula=n(),
            edad.media.tit = mean(edad,na.rm=T),
            muni.local=round(sum(mm,na.rm=T)/n.titula,2),
            prov.local=round(sum(pm,na.rm=T)/n.titula,2))
bd <- merge(bd,hh,by="cod_titulacion",all.x = TRUE)
bd.ucm <- bd

# UAM
# ==================
bd <- uam
bd <- bd[!is.na(bd$des_titulacion),]
bd <- bd[bd$num_total_creditos_mat_curso!=0,]
bd <- bd[bd$ind_se_titula_curso=="NO",]
bd <- bd[bd$num_total_creditos_transf_inicio==0,]
bd <- bd[bd$num_total_creditos_rec_conv_inicio==0,]
bd <- bd[(bd$num_creditos_mat_1_curso==bd$num_total_creditos_mat_inicio),]
bd <- bd[,c(2,4,26,28,42,43,47,51:63,81)]
bd$adscrito <- as.factor(!str_detect(bd$des_centro,"Facultad"))
bd$des_genero <- as.factor(bd$des_genero)
bd$curso_academico <- as.factor(bd$curso_academico)
bd$cod_universidad <- as.factor(bd$cod_universidad)
bd$doble <- as.factor(str_detect(bd$des_titulacion," / "))
bd$mm <- bd$des_municipio_residencia=="MADRID"
bd$pm <- bd$des_provincia_residencia=="Madrid"
hh <- bd %>% group_by(cod_titulacion) %>% 
  summarise(n.titula=n(),
            edad.media.tit = mean(edad,na.rm=T),
            muni.local=round(sum(mm,na.rm=T)/n.titula,2),
            prov.local=round(sum(pm,na.rm=T)/n.titula,2))
bd <- merge(bd,hh,by="cod_titulacion",all.x = TRUE)
bd.uam <- bd

# Alumnos de primero
# UVa
# ====================
bd <- uva
bd <- bd[!is.na(bd$des_titulacion),]
bd <- bd[bd$num_total_creditos_mat_curso!=0,]
bd <- bd[bd$ind_se_titula_curso=="NO",]
bd <- bd[bd$num_total_creditos_transf_inicio==0,]
bd <- bd[bd$num_total_creditos_rec_conv_inicio==0,]
bd <- bd[(bd$num_creditos_mat_1_curso==bd$num_total_creditos_mat_inicio),]
bd <- bd[,c(2,4,26,28,42,43,47,51:63,81)]
bd$adscrito <- as.factor(str_detect(bd$des_centro,c("ADSCRITA|Adscrita")))
bd$des_genero <- as.factor(bd$des_genero)
bd$curso_academico <- as.factor(bd$curso_academico)
bd$cod_universidad <- as.factor(bd$cod_universidad)
bd$doble <- as.factor(str_detect(bd$des_titulacion,"Doble|conjunto"))
bd$mm <- bd$des_municipio_residencia=="VALLADOLID"
bd$pm <- bd$des_provincia_residencia=="Valladolid"
hh <- bd %>% group_by(cod_titulacion) %>% 
  summarise(n.titula=n(),
            edad.media.tit = mean(edad,na.rm=T),
            muni.local=round(sum(mm,na.rm=T)/n.titula,2),
            prov.local=round(sum(pm,na.rm=T)/n.titula,2))
bd <- merge(bd,hh,by="cod_titulacion",all.x = TRUE)
bd.uva <- bd

# Alumnos de primero
# UC3M
# ====================
bd <- uc3m
bd <- bd[!is.na(bd$des_titulacion),]
bd <- bd[bd$num_total_creditos_mat_curso!=0,]
bd <- bd[bd$ind_se_titula_curso=="NO",]
bd <- bd[bd$num_total_creditos_transf_inicio==0,]
bd <- bd[bd$num_total_creditos_rec_conv_inicio==0,]
bd <- bd[(bd$num_creditos_mat_1_curso==bd$num_total_creditos_mat_inicio),]
bd <- bd[,c(2,4,26,28,42,43,47,51:63,81)]
bd$adscrito <- as.factor(str_detect(bd$des_centro,c("Guardia Civil")))
bd$des_genero <- as.factor(bd$des_genero)
bd$curso_academico <- as.factor(bd$curso_academico)
bd$cod_universidad <- as.factor(bd$cod_universidad)
bd$doble <- as.factor(str_detect(bd$des_titulacion,"Doble"))
bd$mm <- bd$des_municipio_residencia=="MADRID"
bd$pm <- bd$des_provincia_residencia=="Madrid"
hh <- bd %>% group_by(cod_titulacion) %>% 
  summarise(n.titula=n(),
            edad.media.tit = mean(edad,na.rm=T),
            muni.local=round(sum(mm,na.rm=T)/n.titula,2),
            prov.local=round(sum(pm,na.rm=T)/n.titula,2))
bd <- merge(bd,hh,by="cod_titulacion",all.x = TRUE)
bd.uc3m <- bd

# Alumnos de primero
# URJC
# ====================
bd <- urjc
bd <- bd[!is.na(bd$des_titulacion),]
bd <- bd[bd$num_total_creditos_mat_curso!=0,]
bd <- bd[bd$ind_se_titula_curso=="NO",]
bd <- bd[bd$num_total_creditos_transf_inicio==0,]
bd <- bd[bd$num_total_creditos_rec_conv_inicio==0,]
bd <- bd[(bd$num_creditos_mat_1_curso==bd$num_total_creditos_mat_inicio),]
bd <- bd[,c(2,4,26,28,42,43,47,51:63,81)]
##
bd$adscrito <- as.factor(str_detect(bd$des_centro,c("CEDEU|IEB|Espectaculos TAI|Escuela Superior ESERP")))
bd$des_genero <- as.factor(bd$des_genero)
bd$curso_academico <- as.factor(bd$curso_academico)
bd$cod_universidad <- as.factor(bd$cod_universidad)
bd$doble <- as.factor(str_detect(bd$des_titulacion,"DOBLE"))
bd$mm <- bd$des_municipio_residencia=="MADRID"
bd$pm <- bd$des_provincia_residencia=="Madrid"
hh <- bd %>% group_by(cod_titulacion) %>% 
  summarise(n.titula=n(),
            edad.media.tit = mean(edad,na.rm=T),
            muni.local=round(sum(mm,na.rm=T)/n.titula,2),
            prov.local=round(sum(pm,na.rm=T)/n.titula,2))
bd <- merge(bd,hh,by="cod_titulacion",all.x = TRUE)
bd.urjc <- bd
rm(bd,hh)
```

```{r identificar rama por titulaciones,echo=FALSE, warning = FALSE, message = FALSE, cache=TRUE}
# UCM
# ==================
ucm.t.1718 <- read.xlsx("Data/ucm-titulaciones-2017-18_0.xlsx")
ucm.t.1920 <- read.xlsx("Data/ucm-titulaciones-2019-20_1.xlsx")
ucm.t.2122 <- read.xlsx("Data/ucm-titulaciones-2021-22.xlsx")
ucm.t.2324 <- read.xlsx("Data/ucm-titulaciones-2023-24.xlsx")
ucm.t <- rbind(ucm.t.1718,ucm.t.1920,ucm.t.2122,ucm.t.2324)
rm(ucm.t.1718,ucm.t.1920,ucm.t.2122,ucm.t.2324)
ucm.t <- ucm.t[ucm.t$des_tipo_estudio=="Grado",]
ucm.t <- ucm.t[,c(3,10,12,13)]
ucm.t <- ucm.t[!duplicated(ucm.t$cod_titulacion),]
ucm.t <- ucm.t[!(ucm.t$cod_titulacion==7000815 & ucm.t$cod_rama==3),]  
bd.ucm <- merge(bd.ucm,ucm.t,by="cod_titulacion")
bd.ucm$des_rama <- as.factor(bd.ucm$des_rama)

# UAM
# ==================
uam.t.1718 <- read.xlsx("Data/uam-titulaciones-2017-18_1.xlsx")
uam.t.1920 <- read.xlsx("Data/uam-titulaciones-2019-20_1.xlsx")
uam.t.2122 <- read.xlsx("Data/uam-titulaciones-2021-22.xlsx")
uam.t.2324 <- read.xlsx("Data/uam-titulaciones-2023-24.xlsx")
uam.t <- rbind(uam.t.1718,uam.t.1920,uam.t.2122,uam.t.2324)
rm(uam.t.1718,uam.t.1920,uam.t.2122,uam.t.2324)
uam.t <- uam.t[uam.t$des_tipo_estudio=="Grado",]
uam.t <- uam.t[,c(3,10,12,13)]
uam.t <- uam.t[!duplicated(uam.t$cod_titulacion),]
uam.t <- uam.t[!(uam.t$cod_titulacion==2502531 & uam.t$cod_rama==1),]  
uam.t <- uam.t[!(uam.t$cod_titulacion==2502958 & uam.t$cod_rama==1),]  
bd.uam <- merge(bd.uam,uam.t,by="cod_titulacion")
bd.uam$des_rama <- as.factor(bd.uam$des_rama)

# UVA
# ==================
uva.t.1718 <- read.xlsx("Data/uva-titulaciones-2017-18_0.xlsx")
uva.t.1920 <- read.xlsx("Data/uva-titulaciones-2019-20_0.xlsx")
uva.t.2122 <- read.xlsx("Data/uva-titulaciones-2021-22.xlsx")
uva.t.2223 <- read.xlsx("Data/uva-titulaciones-2022-23.xlsx")
uva.t <- rbind(uva.t.1718,uva.t.1920,uva.t.2122,uva.t.2223)
rm(uva.t.1718,uva.t.1920,uva.t.2122,uva.t.2223)
uva.t <- uva.t[uva.t$des_tipo_estudio=="Grado",]
uva.t <- uva.t[,c(3,10,12,13)]
uva.t <- uva.t[!duplicated(uva.t$cod_titulacion),]
bd.uva <- merge(bd.uva,uva.t,by="cod_titulacion")
bd.uva$des_rama <- as.factor(bd.uva$des_rama)

# UC3M
# ==================
uc3m.t.1718 <- read.xlsx("Data/uc3m-titulaciones-2017-18_0.xlsx")
uc3m.t.1920 <- read.xlsx("Data/uc3m-titulaciones-2019-20_0.xlsx")
uc3m.t.2122 <- read.xlsx("Data/uc3m-titulaciones-2021-22.xlsx")
uc3m.t.2223 <- read.xlsx("Data/uc3m-titulaciones-2022-23.xlsx")
uc3m.t <- rbind(uc3m.t.1718,uc3m.t.1920,uc3m.t.2122,uc3m.t.2223)
rm(uc3m.t.1718,uc3m.t.1920,uc3m.t.2122,uc3m.t.2223)
uc3m.t <- uc3m.t[uc3m.t$des_tipo_estudio=="Grado",]
uc3m.t <- uc3m.t[,c(3,10,12,13)]
uc3m.t <- uc3m.t[!duplicated(uc3m.t$cod_titulacion),]
bd.uc3m <- merge(bd.uc3m,uc3m.t,by="cod_titulacion")
bd.uc3m$des_rama <- as.factor(bd.uc3m$des_rama)

# URJC
# ==================
urjc.t.1718 <- read.xlsx("Data/urjc-titulaciones-2017-18_2.xlsx")
urjc.t.1920 <- read.xlsx("Data/urjc-titulaciones-2019-20_2.xlsx")
urjc.t.2122 <- read.xlsx("Data/urjc-titulaciones-2021-22_1.xlsx")
urjc.t.2223 <- read.xlsx("Data/urjc-titulaciones-2022-23.xlsx")
urjc.t <- rbind(urjc.t.1718,urjc.t.1920,urjc.t.2122,urjc.t.2223)
rm(urjc.t.1718,urjc.t.1920,urjc.t.2122,urjc.t.2223)
urjc.t <- urjc.t[urjc.t$des_tipo_estudio=="Grado",]
urjc.t <- urjc.t[,c(3,10,12,13)]
urjc.t <- unique(urjc.t)
urjc.t <- urjc.t[!duplicated(urjc.t$cod_titulacion),]
bd.urjc <- merge(bd.urjc,urjc.t,by="cod_titulacion")
bd.urjc$des_rama <- as.factor(bd.urjc$des_rama)
#
bd.t <- rbind(ucm.t,uam.t,uc3m.t,urjc.t,uva.t)
rm(ucm.t,uam.t,uc3m.t,urjc.t,uva.t)
bd.t <- bd.t[!duplicated(bd.t$cod_titulacion), ]
```

```{r datos de acceso, warning = FALSE, echo=FALSE, message = FALSE, cache=TRUE}
# UCM
# ===============
ucm.a.1718 <- read_xlsx("Data/ucm-acceso-2017-18-anonimizado_0.xlsx")
ucm.a.1819 <- read_xlsx("Data/ucm-acceso-2018-19-anonimizado_0.xlsx")
ucm.a.1920 <- read_xlsx("Data/ucm-acceso-2019-20-anonimizado_0.xlsx")
ucm.a.2021 <- read_xlsx("Data/ucm-acceso-2020-21-anonimizado_0.xlsx")
ucm.a.2122 <- read_xlsx("Data/ucm-acceso-2021-22-anonimizado_0.xlsx")
ucm.a.2223 <- read_xlsx("Data/ucm-acceso-2022-23-anonimizado.xlsx")
ucm.a <- rbind(ucm.a.1718,ucm.a.1819,ucm.a.1920,ucm.a.2021,ucm.a.2122,ucm.a.2223)
rm(ucm.a.1718,ucm.a.1819,ucm.a.1920,ucm.a.2021,ucm.a.2122,ucm.a.2223)
ucm.a$uni.madre <- (ucm.a$des_nivel_estudios_madre=="Estudios Superiores")
ucm.a$uni.padre <- (ucm.a$des_nivel_estudios_padre=="Estudios Superiores")
hh <- ucm.a %>% group_by(cod_titulacion) %>% 
  summarize(n.acceso = round(n()/6,0), 
            nota.mediana = round(median(nota_admision,na.rm=TRUE),1),
            nota.media = round(mean(nota_admision,na.rm=TRUE),1),
            nota.sd=round(sd(nota_admision,na.rm=TRUE),2),
            nota.min=round(min(nota_admision,na.rm=TRUE),1),
            uni.madre=round(sum(uni.madre,na.rm=TRUE)/n(),2),
            uni.padre=round(sum(uni.padre,na.rm=TRUE)/n(),2))
bd.ucm <- merge(bd.ucm,hh,by="cod_titulacion",all.x = TRUE)

# UAM
# ===============
uam.a.1718 <- read_xlsx("Data/uam-acceso-2017-18-anonimizado_0.xlsx")
uam.a.1819 <- read_xlsx("Data/uam-acceso-2018-19-anonimizado_0.xlsx")
uam.a.1920 <- read_xlsx("Data/uam-acceso-2019-20-anonimizado_0.xlsx")
uam.a.2021 <- read_xlsx("Data/uam-acceso-2020-21-anonimizado_0.xlsx")
uam.a.2122 <- read_xlsx("Data/uam-acceso-2021-22-anonimizado_0.xlsx")
uam.a.2223 <- read_xlsx("Data/uam-acceso-2022-23-anonimizado.xlsx")
uam.a <- rbind(uam.a.1718,uam.a.1819,uam.a.1920,uam.a.2021,uam.a.2122,uam.a.2223)
rm(uam.a.1718,uam.a.1819,uam.a.1920,uam.a.2021,uam.a.2122,uam.a.2223)
uam.a$uni.madre <- (uam.a$des_nivel_estudios_madre=="Estudios Superiores")
uam.a$uni.padre <- (uam.a$des_nivel_estudios_padre=="Estudios Superiores")
hh <- uam.a %>% group_by(cod_titulacion) %>% 
  summarize(n.acceso = round(n()/6,0), 
            nota.mediana = round(median(nota_admision,na.rm=TRUE),1),
            nota.media = round(mean(nota_admision,na.rm=TRUE),1),
            nota.sd=round(sd(nota_admision,na.rm=TRUE),2),
            nota.min=round(min(nota_admision,na.rm=TRUE),1),
            uni.madre=round(sum(uni.madre,na.rm=TRUE)/n(),2),
            uni.padre=round(sum(uni.padre,na.rm=TRUE)/n(),2))
bd.uam <- merge(bd.uam,hh,by="cod_titulacion",all.x = TRUE)

# UVa
# ===============
uva.a.1718 <- read_xlsx("Data/uva-acceso-2017-18-anonimizado_1.xlsx")
uva.a.1819 <- read_xlsx("Data/uva-acceso-2018-19-anonimizado_1.xlsx")
uva.a.1920 <- read_xlsx("Data/uva-acceso-2019-20-anonimizado_1.xlsx")
uva.a.2021 <- read_xlsx("Data/uva-acceso-2020-21-anonimizado_1.xlsx")
uva.a.2122 <- read_xlsx("Data/uva-acceso-2021-22-anonimizado_0.xlsx")
uva.a.2223 <- read_xlsx("Data/uva-acceso-2022-23-anonimizado.xlsx")
uva.a <- rbind(uva.a.1718,uva.a.1819,uva.a.1920,uva.a.2021,uva.a.2122,uva.a.2223)
rm(uva.a.1718,uva.a.1819,uva.a.1920,uva.a.2021,uva.a.2122,uva.a.2223)
uva.a$uni.madre <- (uva.a$des_nivel_estudios_madre=="Estudios Superiores")
uva.a$uni.padre <- (uva.a$des_nivel_estudios_padre=="Estudios Superiores")
uva.a$nota_admision[uva.a$cod_titulacion==2502312] <- 5
hh <- uva.a %>% group_by(cod_titulacion) %>% 
  summarize(n.acceso = round(n()/6,0), 
            nota.mediana = round(median(nota_admision,na.rm=TRUE),1),
            nota.media = round(mean(nota_admision,na.rm=TRUE),1),
            nota.sd=round(sd(nota_admision,na.rm=TRUE),2),
            nota.min=round(min(nota_admision,na.rm=TRUE),1),
            uni.madre=round(sum(uni.madre,na.rm=TRUE)/n(),2),
            uni.padre=round(sum(uni.padre,na.rm=TRUE)/n(),2))
bd.uva <- merge(bd.uva,hh,by="cod_titulacion",all.x = TRUE)

# UC3M
# ===============
uc3m.a.1718 <- read_xlsx("Data/uc3m-acceso-2017-18-anonimizado_0.xlsx")
uc3m.a.1819 <- read_xlsx("Data/uc3m-acceso-2018-19-anonimizado_0.xlsx")
uc3m.a.1920 <- read.xlsx("Data/uc3m-acceso-2019-20-anonimizado_0.xlsx")
uc3m.a.2021 <- read_xlsx("Data/uc3m-acceso-2020-21-anonimizado_0.xlsx")
uc3m.a.2122 <- read_xlsx("Data/uc3m-acceso-2021-22-anonimizado.xlsx")
# uc3m.a.2223 <- read.csv("Data/uc3m-acceso-2022-23-anonimizado.xlsx")
uc3m.a <- rbind(uc3m.a.1718,uc3m.a.1819,uc3m.a.1920,uc3m.a.2021,uc3m.a.2122)#,uc3m.a.2223)
rm(uc3m.a.1718,uc3m.a.1819,uc3m.a.1920,uc3m.a.2021,uc3m.a.2122)
uc3m.a$uni.madre <- (uc3m.a$des_nivel_estudios_madre=="Estudios Superiores")
uc3m.a$uni.padre <- (uc3m.a$des_nivel_estudios_padre=="Estudios Superiores")
uc3m.a$nota_admision[uc3m.a$des_centro=="Centro Universitario Guardia Civil"] <- 5
hh <- uc3m.a %>% group_by(cod_titulacion) %>% 
  summarize(n.acceso = round(n()/6,0), 
            nota.mediana = round(median(nota_admision,na.rm=TRUE),1),
            nota.media = round(mean(nota_admision,na.rm=TRUE),1),
            nota.sd=round(sd(nota_admision,na.rm=TRUE),2),
            nota.min=round(min(nota_admision,na.rm=TRUE),1),
            uni.madre=round(sum(uni.madre,na.rm=TRUE)/n(),2),
            uni.padre=round(sum(uni.padre,na.rm=TRUE)/n(),2))
bd.uc3m <- merge(bd.uc3m,hh,by="cod_titulacion",all.x = TRUE)

# URJC
# ===============
urjc.a.1718 <- read_xlsx("Data/urjc-acceso-2017-18-anonimizado_0.xlsx")
urjc.a.1819 <- read_xlsx("Data/urjc-acceso-2018-19-anonimizado_0.xlsx")
urjc.a.1920 <- read_xlsx("Data/urjc-acceso-2019-20-anonimizado_0.xlsx")
urjc.a.2021 <- read_xlsx("Data/urjc-acceso-2020-21-anonimizado_0.xlsx")
urjc.a.2122 <- read_xlsx("Data/urjc-acceso-2021-22-anonimizado_0.xlsx")
urjc.a.2223 <- read_xlsx("Data/urjc-acceso-2022-23-anonimizado.xlsx")
urjc.a <- rbind(urjc.a.1718,urjc.a.1819,urjc.a.1920,urjc.a.2021,urjc.a.2122,urjc.a.2223)
rm(urjc.a.1718,urjc.a.1819,urjc.a.1920,urjc.a.2021,urjc.a.2122,urjc.a.2223)
urjc.a$uni.madre <- (urjc.a$des_nivel_estudios_madre=="Estudios Superiores")
urjc.a$uni.padre <- (urjc.a$des_nivel_estudios_padre=="Estudios Superiores")
hh <- urjc.a %>% group_by(cod_titulacion) %>% 
  summarize(n.acceso = round(n()/6,0), 
            nota.mediana = round(median(nota_admision,na.rm=TRUE),1),
            nota.media = round(mean(nota_admision,na.rm=TRUE),1),
            nota.sd=round(sd(nota_admision,na.rm=TRUE),2),
            nota.min=round(min(nota_admision,na.rm=TRUE),1),
            uni.madre=round(sum(uni.madre,na.rm=TRUE)/n(),2),
            uni.padre=round(sum(uni.padre,na.rm=TRUE)/n(),2))
bd.urjc <- merge(bd.urjc,hh,by="cod_titulacion",all.x = TRUE)
```

```{r Estructura del PDI, warning = FALSE, echo=FALSE, message = FALSE, cache=TRUE}
uam.pdi <- read_xlsx("Data/uam-personal-pdi-2022-anonimizado.xlsx")
uc3m.pdi <- read_xlsx("Data/uc3m-personal-pdi-2022-anonimizado.xlsx")
ucm.pdi <- read_xlsx("Data/ucm-personal-pdi-2022-anonimizado.xlsx")
uva.pdi <- read_xlsx("Data/uva-personal-pdi-2022-anonimizado.xlsx")
urjc.pdi <- read_xlsx("Data/urjc-personal-pdi-2022-anonimizado.xlsx")
pdi <- rbind(uam.pdi,uc3m.pdi,ucm.pdi,uva.pdi,urjc.pdi)[,c(2,3,23,26,27)]

xx <- table(pdi$des_categoria_cuerpo_escala,pdi$cod_universidad)
xx <- matrix(xx, ncol = ncol(xx), dimnames = dimnames(xx))
xx <- (t(xx)/colSums(xx))
xx <- data.frame(cod_universidad=row.names(xx),xx)
```

```{r join data sets, warning = FALSE, echo=FALSE, message = FALSE}
bd <- rbind(bd.ucm,bd.uam,bd.uva,bd.uc3m,bd.urjc)
# join PDI
bd <- merge(bd,xx, by="cod_universidad",all.x = TRUE)

hh <- bd %>% group_by(des_titulacion,cod_universidad) %>% 
  summarize(n=n(),
            cre=mean(num_total_creditos_mat_curso,na.rm=T),
            max=max(num_total_creditos_mat_curso,na.rm=T),
            min=min(num_total_creditos_mat_curso,na.rm=T))

bd <- bd[(bd$num_total_creditos_mat_curso < 91) &
            (bd$num_total_creditos_mat_curso >= 30),]
bd$des_titulacion <- as.factor(bd$des_titulacion)
bd$cod_titulacion <- as.factor(bd$cod_titulacion)
bd <- bd[!is.na(bd$nota.mediana),]
```

```{r fracaso indicadores, echo=FALSE, warning = FALSE, message = FALSE, cache=TRUE}
# Tasa rendimiento
bd$tr <- bd$num_total_creditos_sup_curso/bd$num_total_creditos_mat_curso
# # Tasa éxito
bd$te <- bd$num_total_creditos_sup_curso/bd$num_creditos_pres_curso
# # Tasa evaluación
# bd$tev <- bd$num_creditos_pres_curso/bd$num_total_creditos_mat_curso

bd$abandono <- as.factor(bd$tr <= 24/60)
levels(bd$abandono) <- c("NO","SI")
# table(bd$abandono)/dim(bd)[1]
levels(bd$des_rama) <- c("AH","Ci","CS","CSJ","IA")
```

```{r leer datos simplificado, echo=FALSE, eval=FALSE}
# Lectura de datos
# ==============================================================================
load("~/Library/CloudStorage/Dropbox/UniversiDATA/Univerdidata.RData")
```


# Introducción

El abandono universitario representa uno de los problemas más desafiantes que enfrenta la educación superior a nivel global, convirtiéndose en una prioridad estratégica para los sistemas universitarios en todo el mundo [@constante2021;@kehm2019;@jia2015;@delogu2024; @nunez2024]. La proporción de estudiantes que no completan un programa de grado universitario dentro de la duración teórica varía desde menos del 20% en el Reino Unido, Israel, Suiza e Irlanda, hasta más del 40% en Brasil, Eslovenia, Chile, Bélgica (comunidad francófona), Suecia, Italia, Austria y Estonia [@aina2022]. Este fenómeno, que tiene fuertes implicaciones tanto para los estudiantes y sus familias como para las instituciones y la sociedad en general se ha mantenido de manera persistente sin que se hayan identificado soluciones claras para reducir su impacto. En un mundo donde el capital humano es esencial para el desarrollo económico y social, la retención estudiantil debe ser una prioridad para todos los sistemas educativos, incluida la educación superior.

La búsqueda de soluciones a un problema que, de manera persistente, se repite año tras año en las universidades ha generado una extensa producción de literatura científica. Estos estudios han abordado el fenómeno desde múltiples perspectivas, presentando tanto análisis generales [@lorenzoquiles2023;@aina2022] como casos específicos en diferentes universidades y titulaciones [@seo2024; @espinoza2024]. Aunque existe una gran heterogeneidad en las investigaciones, en general, todas convergen en la identificación de un problema que es multifactorial y que está influenciado por una combinación de factores personales, sociales, económicos e institucionales [@constante2021]. 

Hay un elevado número de estudios identifican elementos individuales como el género [@espinoza2024], la edad [@behr2020review], el origen geográfico [@delogu2024; @constante2021], la capacidad académica [@serrano2013], la motivación [@delacruzcampos2023], la salud mental [@kawada2014], el rendimiento académico previo [@bernardo2021], la vocación o las expectativas profesionales [@bernardo2021; @belloc2010]. Todos estos factores, en mayor o menor medida, son determinantes del abandono de los estudios universitarios. 

El estatus socioeconómico y el entorno familiar también tiene un papel crucial. @palacio2020 realiza un estudio bibliométrico centrado impacto de las variables socioeconómicas y sociodemográficas como causantes del bajo rendimiento y del consecuente abandono. En general los estudios coinciden en que los estudiantes de familias con menores ingresos enfrentan mayores barreras financieras y suelen tener menor acceso a recursos de apoyo. Además, los costos de matrícula y manutención pueden ser insostenibles para muchos, especialmente en países con sistemas de educación superior menos accesibles. En este grupo de factores @walsh2016 señala la importancia de los estudios realizados por los padres como factor vinculado al menor nivel de abandono de los estudios universitarios. En la misma línea, @aina2013 analiza el caso italiano. @contini2018 explora una muestra amplia de estudiantes de las universidades de Italia y destaca la importancia que tiene el nivel educativo de los progenitores en el abandono. En el caso español el informe de 2024 del Ministerio de Ciencia Innovación y Universidades también traza un completo análisis socioeconómico del estudiantado [@perfil_socioeconomico_2024].

El diseño del sistema educativo también impacta el abandono. Los sistemas con menor flexibilidad curricular, altos requisitos académicos y pocos programas de apoyo suelen tener tasas más altas de deserción. Aspectos institucionales y estructurales, como la calidad del apoyo estudiantil y las políticas de retención implementadas por las universidades [@behr2022; @galve2024]. La integración social y académica también es determinante [@tinto1975] cuando los estudiantes no logran establecer conexiones con el entorno universitario. Por su parte, @behr2022 destacan el papel de las políticas institucionales, incluyendo la orientación y el apoyo estudiantil, como elementos clave para mejorar la retención.

También todas estas investigaciones coinciden en que es en el primer año de estudios universitarios donde principalmente se produce el abandono de los estudios [@rodriguez2019; @goller2023]. Aunque es un fenómeno que también tiene lugar en los siguientes años, su incidencia es menor. Las diferencias entre ramas de conocimiento son indudables, encabezadas por las llamadas titulaciones STEM (Ciencia, Tecnología, Ingeniería y Matemáticas, por sus siglas en inglés), que por otra parte son aquellas en las que se necesita mayor capital humano para adaptarse al imparable proceso de digitalización de la economía y de todas las actividades diarias.

Un enfoque metodológico que se ha prevalecido en los estudios que buscan soluciones al abandono universitario ha sido el uso de métodos estadísticos para identificar y cuantificar los factores determinantes. Sin embargo, en los últimos años, el creciente volumen de datos y el avance de los algoritmos de aprendizaje automático (ML, por sus siglas en inglés) han otorgado un nuevo impulso a estas investigaciones. Nuestra propuesta de investigación va en esta línea en busca de contribuir al conocimiento del fenómeno en el caso español. Aprovechamos la iniciativa **UniversiDATA**, que recopila microdatos detallados de estudiantes de 5 universidades a lo largo de seis cursos académicos, para aplicar algoritmos de Machine Learning que identifiquen patrones clave y profundicen en la comprensión del abandono en el contexto español.

Este artículo se estructura en 5 secciones. El la segunda sección se presenta una breve revisión de la literatura centrada en recopilar trabajos sobre abandono en los que se utilicen técnicas de ML. En la sección tercera se presenta la base de datos y la metodología. En la cuarta los resultados y la quinta sección concluye.

# Revisión de la literatura

Debido a la gran relevancia del problema del abandono en el sistema universitario, la producción científica, tanto a nivel internacional como nacional, es enorme. Varios artículos han recopilado investigaciones internacionales que abordan esta cuestión desde diferentes ángulos [@behr2020review; @lorenzoquiles2023; @aina2022; @delacruzcampos2023; @alban2019a]. En el caso español, @alvarez2021 destaca estudios sobre abandono en universidades presenciales. @delacruzcampos2023 realiza un análisis sistemático de estudios sobre el abandono universitario, con especial énfasis en Andalucía. @ortiz2020 analiza cómo los datos sociodemográficos y académicos pueden predecir el abandono temprano. En Educación XX1 @constante2021 analiza los factores asociados al abandono universitario en el caso de en la Universidad Complutense de Madrid. Algunas revistas también editaron un monográfico, dirigido por @bravo2015, que trata el problema desde múltiples perspectivas. Además de todas estas investigaciones, diversas instituciones han elaborado informes en los que se aborda el abandono universitario: el Ministerio de Universidades [@mellizo2022], la Confederación de Rectores de las Universidades Españolas (CRUE)^[https://www.crue.org/wp-content/uploads/2024/06/UEC-24_Avance-04.pdf], el Ministerio de Ciencia, Innovación y Universidades [@perfil_socioeconomico_2024], incluso el Consejo Social de la Universidad Carlos III de Madrid elaboró dos informes en 2014 y 2019 [@uc3m2019;@uc3m2014] para analizar esta problemática.

<!-- También hay un gran número de investigaciones centradas en países concretos: @seo2024 en Corea del Sur; @toyon2024 en Estonia; @espinoza2024 en Chile; y @nunez2024 en Ecuador. -->

## Investigaciones que aplican algoritmos de ML

Para investigar los determinantes del abandono universitario, investigaciones previas han empleado modelos econométricos estándar, como Mínimos Cuadrados Ordinarios (OLS), Modelos Lineales Generalizados (GLM) o modelos de datos panel [@aina2013; @belloc2010]. Sin embargo, existe ahora un consenso de que estas herramientas no son intrínsecamente predictivas, lo que ha llevado a muchos autores a sugerir el uso de algoritmos de ML para abordar el problema del abandono universitario. La literatura recoge una amplia variedad de técnicas, que van desde las más clásicas como la regresión logística [@cho2023; @jia2015] pasando por toda una variedad de algoritmos como Naïve Bayes [@kotsiantis2004], k-means [@erdogan2005], árboles de decisión [@segura2022; @sung2009; @kabra2011], redes neuronales [@alban2019b], Random Forest [@behr2020randomforest; @urbina2020], Support Vector Machine [@cho2023], o incluso métodos de procesamiento de lenguaje natural [@won2023]. Todas ellas han mostrado ser altamente efectivas en el análisis y predicción de este fenómeno.

Son frecuentes las investigaciones que utilizan varios algoritmos de ML comparando los resultados que ofrecen cada uno de ellos. Por ejemplo, @yu2010 analiza el abandono a través de árboles de clasificación, MARS y redes neuronales. @kim2023 utiliza modelos basados Análisis de Compontenes Principales y  K-means clustering para mejorar las predicciones. @kabathova2021 aplica seis de los algoritmos más conocidos de ML para comparar la capacidad predictiva de cada uno de ellos. @cho2023 también utiliza una amplia batería de algoritmos Regresión Logística, Árboles de Decisión, Random Forest, Support Vector Machine, Deep Neural Network, and LightGBM (Light Gradient Boosting Machine) siendo este último el que mejor resultados ofrece. @delogu2024 aplica 5 algoritmos (Logistic, RF, GBM, NN, LASSO) a una gran base de datos de 230.336 universitarios italianos. 

En general todos los algoritmos mostraron buenas capacidades de predicción sin que a prori exista un claro modelo ganador.

<!-- A pesar del elevado volumen de investigaciones sobre este tópico, los avances significativos siguen siendo limitados y enfrentan retos en todos los niveles de datos educativos. Aunque ya se han analizado diversas características, sigue abierta la cuestión de cuáles son las más apropiadas para los diferentes clasificadores de ML -->

<!-- Por ejemplo, con el objetivo de mejorar la retención de estudiantes, @lin2012 estudió una variedad de algoritmos de ML para desarrollar modelos predictivos basados en los datos de los estudiantes que ingresan. Como resultado, los modelos pueden proporcionar precisión a corto plazo para predecir qué tipos de estudiantes se beneficiarían de los programas de retención en el campus. 

@behr2020randomforest presenta una investigación relevante mediante árboles de decisión ya que analiza el proceso de abandono en tres etapas, centrándose en la predicción temprana del abandono mediante un modelado progresivo de la transición de los estudiantes desde la escuela secundaria (fase previa), pasando por la fase de decisión de estudios (fase de decisión), hasta los primeros semestres en la universidad (fase inicial de estudios).

@song2023 destaca cómo un algoritmo de selección de atributos permitió identificar factores clave que influyen en el abandono. Usando árboles de decisión, se definieron patrones para alertar sobre un abandono inminente. Una herramienta adaptada fue administrada en línea a 300 estudiantes de instituciones públicas y 200 de privadas en programas de educación superior. Los resultados evidenciaron que el algoritmo Random Forest fue el más preciso para identificar estudiantes en riesgo de abandono, subrayando su utilidad para desarrollar intervenciones efectivas. -->

# Datos y metodología




```{r leer datos, echo=FALSE,cache=FALSE, warning=FALSE,message=FALSE}
library(here)
# Lectura de datos
# ==============================================================================
load(here("Univerdidata_bd.RData"))
```

```{r librerias, echo=FALSE, warning=FALSE, message=FALSE}
library(earth)
library(dplyr)
library(ROCR)
library(pROC)
library(ranger)
library(ggplot2)
library(tidyverse)
# summary(bd$Profesor.Ayudante.Doctor)
names(bd)[names(bd) == "Profesor.Ayudante.Doctor"] <- "PAyuDoc"
names(bd)[names(bd) == "Profesor.Asociado"] <- "PAsoc"
names(bd)[names(bd) == "cod_Universidad"] <- "Universidad"
names(bd)[names(bd) == "des_rama"] <- "Rama"
```

## Datos y estadísticas descriptivas

Esta investigación analiza la base de datos abierta más extensa que recopila y ofrece datos estadísticos sobre universidades en España. Hasta donde sabemos la más completa y extensa disponible en España y solo puede compararse en tamaño de información con la reciente publicación de @delogu2024. Cinco universidades son incluidas en el estudio: la Universidad Autónoma de Madrid, la Universidad Complutense de Madrid, la Universidad Carlos III de Madrid, la Universidad Rey Juan Carlos y la Universidad de Valladolid. Los datos analizados abarcan seis cursos académicos, desde 2017-2018 hasta 2022-2023. Los conjuntos de datos están anonimizados para proteger la privacidad de los individuos y han sido puestos en abierto con el objetivo de facilitar el desarrollo de políticas educativas basadas en la evidencia del dato. Toda la información se encuentra disponible de forma abierta en el portal **UniversiDATA**^[https://www.universidata.es/].

Nuestra investigación se centra en los estudiantes de primer curso que se matriculan por primera vez en la universidad ya que es en este primer contacto del estudiante con el entorno universitario cuando se produce la mayor tasa de abandono. Tras un cuidadoso proceso de ingeniería de datos se seleccionaron un total de  203.941 estudiantes que cumplían los requisitos. Asociados a estos individuos se seleccionaron de diversas bases de datos disponibles en el portal varios factores que la literatura ha asociado al abandono.

La  Tabla \ref{tab:variables} lista las variables seleccionadas para esta investigación con una breve descripción. Para caa uno de los estudiantes se calculó la tasa de rendimiento (TR) del primer año y se planteó la hipótesis de que una mayor tasa de rendimiento (TR) en el primer curso reduce la probabilidad de abandono. El rendimiento académico del estudiante en el primer año, medido como el porcentaje de créditos aprobados respecto al total matriculado (TR04), es la variable que, con diferencia, tiene más peso en el abandono. Este hallazgo confirma que la *integración académica* propuesta por @tinto1975 tiene una relevancia crucial. Sin embargo, hay que interpretar este resultado con cautela, ya que la propia decisión de abandonar podría anteceder al bajo rendimiento. Es decir, un estudiante que ya haya decidido abandonar podría no esforzarse en los exámenes. Basándonos en esta hipótesis consideramos que un estudiante de primer grado se considera que ‘abandona’ los estudios si su tasa de rendimiento es inferior a 0,4. Un total de 11,9% del los estudiantes cumplen esta condición.^[Advertencia: La definición de abandono es un proxy asociado a la tasa de rendimiento. Es una aproximación pobre y aunque existe alta correlación entre la tasa de rendimiento y el abandono hay varias cuestiones que pueden plantearse: La relación causal es compleja. Objetivo: visibilizar el problema del abandono].

La Tabla \ref{tab:estudiantes} muestra la distribución porcentual de las variables categóricas (factores) del estudiante dependiendo de si la tasa de rendimiento es o no inferior a 0,4 (TR04). Los resultados observados muestran fuertes diferencias, por ejemplo, los estudiantes matriculados en centros adscritos presentan valores de TR04 inferiores a los no adscritos. El género es otro factor que genera grandes diferencias, en el conjunto de datos hay 121358 mujeres (el 59,8%) de las cuales solo un 8,85% tienen TR<0,4 mientras que el 16,75% presentan tasas de rendimiento iguales o superiores. Esta diferencias en género son similares a las identificadas en el caso italiano [@delogu2024]. También la rama de conocimiento asociada a la titulación en la que el estudiante está matriculado se observan diferencias muy grandes en la variable TR04. En IA hay un 24,76% de estudiantes con TR<0,4 frente al 7,81 en CS. Finalmente, la Tabla \ref{tab:histogramas} muestra la distribución de las variables asociadas a la titulación que cursa el estudiante.



```{=tex}
\begin{table}[htbp]
\centering
\small
\caption{Descripción de las variables (N = 203.941)}
\begin{tabular}{p{2cm}p{10cm}p{3cm}}
\hline
\textbf{Variable} & \textbf{Descripción} & \textbf{Media(dt)} \\ \hline
\multicolumn{3}{l}{\textbf{Variable Dependiente}} \\ \hline
TR04 &  1 si la tasa de rendimiento del estudiante es inferior a 0.4; 0 en otro caso & 0.119 ()\\ \hline
\multicolumn{3}{l}{\textbf{Variables independientes}} \\ \hline
Género &  1 si es mujer; 0 en otro caso & 0.595  ()\\ 
Adscrito & 1 si está matriculado en un centro adscrito; 0 en otro caso & 0.078 ()\\ \hline
Doble &  1 si el estudiante está matriculado en un doble grado; 0 en otro caso & 0.119  ()\\ 
Rama & Factor con 5 categorías para cada una de las ramas de conocimiento correspondiente a la titualción en la que el estudiante está matriculado: AH Artes y Humanidades; Ci Ciencias; CS Ciencias de la Salud; CSJ Ciencias Sociales y Jurídicas; IA Ingeniería y Arquitéctura & AH 0.116; Ci 0.077; CS 0.131; CSJ   0.554; IA 0.121 \\ 
Universidad & Factor con 5 categorías identificando la universidad (UCM U. Complutense de MAdrid; AUM U. Autónoma de Madrid; UC3M U. Carlos III de Madrid; URJC U. Rey Juan Carlos; UVa U. de Valladolid) & UCM 0.362; UAM 0.167; UC3M 0.125; URJC 0.227; UVa 0.119 \\ \hline
\multicolumn{3}{p{15cm}}{\textbf{Dato imputado al estudiante según la titulación que cursa y el curso académico en el que se matricula}} \\ 
\hline
nacceso & Número medio de alumnos que acceden a cada titulación & 304,9 (330,3)  \\ 
EdadMedia & Edad media de los alumnos de la titulación & 22,35 (1,158) \\ 
Municipio & Porcentaje de estudiantes que residen en el mismo municipio en cada titulación & 0.350 (0.091)\\ 
Provincia & Porcentaje de estudiantes que residen en la misma provincia en cada titulación & 0.697 (0.157)\\
NotaMediana & Nota mediana de acceso a la titulación que cursa el estudiante & 10.299; (1.669) \\
NotaMin & Nota mínima de acceso a la titulación que cursa el estudiante & media=5.168 \\ 
MadreUniv & Porcentaje de estudiantes cuya madre tiene estudios universitarios en la titulación en la que está matriculado el alumno & 0.395 () \\ 
PadreUniv & Porcentaje de estudiantes cuyp padre tiene estudios universitarios en la titulación en la que está matriculado el alumno & 0.356 () \\
\hline
\multicolumn{3}{p{15cm}}{\textbf{Dato imputado al estudiante según la universidad en la que está matriculado y curso académico}} \\ 
\hline
Ayudantes & Porcentaje de profesorado ayudante doctor sobre el total de profesorado de la universidad &0.094 (0.028) \\
Asociados & Porcentaje de profesorado asociado sobre el total de profesorado de la universidad &0.248 (0.089)\\
\hline
\multicolumn{3}{p{15cm}}{  \scriptsize Valores medios y desviaciones típicas son globales para todos los cursos académcios y todas las titualciones}\\
\multicolumn{3}{p{15cm}}{ \scriptsize{Tasa de rendimiento = número de créditos superados entre el número de créditos matriculados. Los datos se filtraron para solo considerar estudiantes cuyo número total de créditos matriculados estuviera en entre 30 y 90 ambos valores incluidos}}
\end{tabular}
\label{tab:variables}
\end{table}

```


```{r plots, warning=FALSE,message=FALSE, echo=FALSE,fig.height=5, fig.cap="\\label{fig:plots} Histogramas número de observaciones. Rama de Conocimiento (Izda) y Universidad (Dcha)"}
levels(bd$cod_universidad) <- c("UCM","UAM","UVa","UC3M","URJC")
data <- as.data.frame(table(bd$cod_universidad))
colnames(data) <- c("Universidad","Estudiantes")
p1 <- ggplot(data, aes(x = Universidad, y = Estudiantes, fill = Universidad)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(title = "",x = "",y = "") +
  scale_fill_brewer(palette = "Set1") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

data <- as.data.frame(table(bd$Rama))
colnames(data) <- c("Rama","Estudiantes")
p2 <- ggplot(data, aes(x = Rama, y = Estudiantes, fill = Rama)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(
    title = "",
    x = "",
    y = "Número de Estudiantes"
  ) +
  scale_fill_brewer(palette = "Set2") +
  theme(axis.text.x = element_text(angle = 0, hjust = 1))

data <- as.data.frame(table(bd$adscrito))
colnames(data) <- c("Si","No")
p3 <- ggplot(data, aes(x = 2, y = Frecuencia, fill = Variable)) +
  coord_polar(theta = "y") +
  xlim(0.5, 2.5) +
  theme_void() +
  theme(legend.title = element_blank(),
        plot.title = element_text(hjust = 0.5, size = 16)) +
  geom_text(aes(label = paste0(round(Porcentaje, 1), "%")), 
            position = position_stack(vjust = 0.5), color = "white")

library(ggExtra)
library(ggpubr)
ggarrange(p2, p1,ncol=2, nrow=2)
```

```{r, eval=FALSE, warning=FALSE,message=FALSE, echo=FALSE, cache=TRUE}
library(dplyr)
hyper_grid <- expand.grid(
  degree = 1:2, 
  nprune = seq(15,30, length.out = 4) 
)

set.seed(123)  # for reproducibility
tic()
tuned_mars <- train(
  x = bd[,all.vars(formula)[-1]],
  y = bd$abandono,
  method = "earth",
  trControl = trainControl(method = "cv", number = 10),
  tuneGrid = hyper_grid)
toc()
# best model
tuned_mars$bestTune
# plot results
ggplot(tuned_mars)
```


```{r busqueda hiperparametros, eval=FALSE, echo=FALSE, cache=TRUE}
# Busqueda hiperparametros MARS
# ==================================================
set.seed(123)
library(rsample)
library(ROCR)
train <- initial_split(bd, prop = .7, strata = abandono)
bd_train <- training(train)
bd_test <- testing(train)
hyper_grid <- expand.grid(
  degree = 1:2,
  thresh = c(0.005,0.001),
  minspan = c(3000,5000,8000),
  nprune = c(20,25,30)
  )
MYMARS <- list()
AUC <- list()
for (i in 1:dim(hyper_grid)[1]){
formula <- abandono ~ des_genero + doble + Rama + adscrito + cod_universidad + 
  n.acceso + edad.media.tit + muni.local + prov.local + nota.mediana + nota.min + uni.padre + uni.madre + PAsoc + PAyuDoc
 MYMARS[[i]] <- earth(formula, data = bd_train, 
                      degree = hyper_grid[i,1],
                      thresh = hyper_grid[i,2],
                      minspan = hyper_grid[i,3],
                      nprune = hyper_grid[i,4],
                      endspan = 1000,
                      glm=list(family=binomial))
predicciones <- predict(MYMARS[[i]], newdata = bd_test, type = "response")
# class_pred <- ifelse(predicciones > 0.2, 1, 0)
# table(bd_test$abandono,class_pred)
pred <- prediction(predicciones, bd_test$abandono)
perf <- performance(pred, "tpr", "fpr")  # tpr: tasa de verdaderos positivos, fpr: tasa de falsos positivos
# Calcular el AUC
auc <- performance(pred, "auc")
auc <- performance(pred, "auc")
auc_value <- auc@y.values[[1]]
print(hyper_grid[i,])
print(paste("AUC:", auc_value))
AUC[[i]] <- auc_value
}
# Ojo sale un poc mejor con 5000 (habra que cambiarlo)
```


```{r MARS abandono, echo=FALSE, cache=TRUE}
bd$abandono <- as.factor(bd$tr <= 24/60)
formula <- abandono ~ des_genero + doble + Rama + adscrito + cod_universidad + 
  n.acceso + edad.media.tit + muni.local + prov.local + nota.mediana + nota.min + uni.padre + uni.madre + PAsoc + PAyuDoc
mymars <- earth(formula, data = bd, minspan = 3000, 
                endspan = 1000, degree = 2, nprune = 25,
                glm=list(family=binomial))
# plotmo(mymars)
```

```{r AUC MARS, eval=FALSE, echo=FALSE, cache=TRUE}
predicciones.mymars <- predict(mymars, type = "response")
pred <- prediction(predicciones.mymars, bd$abandono)
perf <- performance(pred, "auc","tpr", "fpr")  # tpr: tasa de verdaderos positivos, fpr: tasa de falsos positivos
auc <- performance(pred, "auc","sens","spec")
auc_value <- auc@y.values[[1]]
```



```{r tabla estudiantes, warning=FALSE,message=FALSE,echo=FALSE}
library(kableExtra)
library(knitr)
levels(bd$cod_universidad) <- c("UCM","UAM","UVa","UC3M","URJC")
levels(bd$adscrito) <- c("No","Si")
levels(bd$doble) <- c("No","Si")

chi <-chisq.test(table(bd$abandono,bd$adscrito))
chi <-chisq.test(table(bd$abandono,bd$des_genero))

tab2 <- as.data.frame(cbind(table(bd$abandono,bd$adscrito),table(bd$abandono,bd$des_genero),table(bd$abandono,bd$doble),table(bd$abandono,bd$cod_universidad),table(bd$abandono,bd$Rama)))
zx <- tab2
tab2 <- t(100*t(t(tab2)/colSums(tab2)))
tab2 <- cbind(rowSums(t(zx)),tab2)
kbl(tab2, col.names = c("N", "$TR04 \\geq 0,4$","$TR04<0,4$"), caption = "Número estudianes (N) y distribución poercentual en base a TR04 \\label{tab:estudiantes}", 
    format.args = list(decimal.mark = ","),align = "c", booktabs = T,format = "latex",digits=2, escape = FALSE) %>%
kable_styling() %>%
  pack_rows("Género (mujer)", 1, 2) %>%
pack_rows("Adscrito", 3, 4) %>%
pack_rows("Doble", 5, 6) %>%
pack_rows("Universidades", 7, 11) %>%
pack_rows("Rama", 12, 16)
```

```{r tabla con graficos, warning=FALSE, message=FALSE,echo=FALSE}
library(kableExtra)
library(knitr)
library(dplyr)
bd_list1 <- split(bd$n.acceso,bd$abandono)
bd_list2 <- split(bd$edad.media.tit,bd$abandono)
bd_list3 <- split(bd$muni.local ,bd$abandono)
bd_list4 <- split(bd$prov.local ,bd$abandono)
bd_list5 <- split(bd$nota.mediana,bd$abandono)
bd_list6 <- split(bd$nota.min,bd$abandono)
bd_list7 <- split(bd$uni.madre ,bd$abandono)
bd_list8 <- split(bd$uni.padre ,bd$abandono)
inline_plot <- data.frame(TR04 = c("Si","No"), nacceso="", EdadMedia="", Municipio="",Provincia ="",NotaMed = "", NotaMin = "",MadreUniv = "",PadreUniv = "")
xa=160
xb=160
inline_plot %>%
  kbl(booktabs = TRUE,format = "latex",caption="Histogramas de las variables correspondientes a la titulación en la que el estudiante está matriculado (Si=TR04<0,4) \\label{tab:histogramas}") %>%
  kable_paper(full_width = FALSE) %>%
  column_spec(2, image = spec_hist(bd_list1,width=xa,height=xb)) %>%
  column_spec(3, image = spec_hist(bd_list2,width=xa,height=xb)) %>%
  column_spec(4, image = spec_hist(bd_list3,width=xa,height=xb) )%>%
  column_spec(5, image = spec_hist(bd_list4,width=xa,height=xb)) %>%
  column_spec(6, image = spec_hist(bd_list5,width=xa,height=xb)) %>%
  column_spec(7, image = spec_hist(bd_list6,width=xa,height=xb)) %>%
  column_spec(8, image = spec_hist(bd_list7,width=xa,height=xb)) %>%
  column_spec(9, image = spec_hist(bd_list8,width=xa,height=xb))
```

```{r logit, warning=FALSE, warning=FALSE, message=FALSE,echo = FALSE}
mylogit <- glm(formula, data=bd,family = "binomial")
# predicted data
predicciones.mylogit <- predict(mylogit, bd,type="response")
# create roc curve
roc_object <- roc(bd$abandono, predicciones.mylogit)
# calculate area under curve
# auc(roc_object)
# myroc <- roc(bd$abandono,predicciones.mylogit) 
# plot(myroc,ylim=c(0,1))
```

## Metodología

Los modelos econométricos quedan a la sombra del creciente boom de los modelos ensamblados y de redes profundas. El mundo los datos masivos ha traído un creciente interés por tipos de modelización que buscan la mayor precisión posible en el resultado. Esta alta precisión en busca de la mejor combinación no lineal hace que la interpretabilidad sea un punto fuerte a desarrollar [@gilpin2018]. Para ello introducimos dentro del proceso de estimación una fase de deslinealización a través de la técnica de Multivariate Adaptive Regression Splines MARS [@m11], aplicado a un modelo de regresión logística, para desarrollar un sistema de alerta temprana que identifique el riesgo de abandono de cada estudiante. A diferencia de otros algoritmos similares, MARS tiene la ventaja de seleccionar automáticamente las variables más relevantes que determinan las probabilidades de abandono, considerando también impactos no lineales de las variables independientes. Una de las principales características de este algoritmo es su fácil interpretación. Esta facilidad de interpretación es crucial, ya que permite a las universidades entender claramente los factores que influyen en el abandono y, por tanto, tomar decisiones rápidas y efectivas para reagrupar a los estudiantes en función de su riesgo.

El algoritmo MARS es una técnica de regresión flexible, no paramétrica y por partes, introducida por @friedman1991. Esta metodología impulsada por datos es especialmente útil para identificar no linealidades en modelos de regresión sin hacer suposiciones previas sobre su forma funcional, las variables explicativas o su número. La característica principal de esta técnica es que el modelo econométrico considera diferentes pendientes de regresión en distintos intervalos para cada predictor. 

A diferencia de técnicas de regresión lineal más conocidas, MARS no asume que los coeficientes sean estables a lo largo del rango de cada variable y, en su lugar, utiliza splines para ajustar funciones continuas por partes. En general, MARS construye una función lineal por partes para capturar relaciones no lineales de manera adaptativa. La principal ventaja de esta metodología, en comparación con algoritmos similares (como modelos polinómicos, LASO o GAM), es la simplicidad del modelo econométrico resultante y su interpretación intuitiva. Además, se ha reportado que los modelos MARS funcionan satisfactoriamente en términos de costo computacional, independientemente de la dimensión del conjunto de datos, destacando la escalabilidad computacional de este algoritmo para tamaños de muestra grandes en comparación con otros algoritmos. 

Información técnica detallada sobre el algoritmo MARS y su aplicación en análisis de datos se puede encontar en @hastie2009elements y @Hoang_et_al_2017.

### Principios Básicos de MARS

Al igual que en cualquier modelo de regresión, el objetivo de esta metodología es construir un modelo econométrico que explique la variación de una variable dependiente $Y = (y_1, \ldots, y_n)'$ con un conjunto de posibles variables explicativas $X = (X_1, \ldots, X_p)$, donde $X_i = (x_{1i}, x_{2i}, \ldots, x_{ni})'$. Para alcanzar este objetivo clásico, MARS utiliza las llamadas funciones básicas (BF) de la forma $(x - c)_{+} = \max\{0, x - c\}$ y $(c - x)_{+} = \max\{0, c - x\}$, donde el subíndice “+” indica que la función toma solo el valor positivo o cero en caso de una diferencia negativa. Tales pares de funciones lineales se denominan funciones de bisagra (o funciones truncadas a ambos lados), y la constante $c$ denota un nudo donde cambia la pendiente. La colección de todas las BF posibles, $\mathcal{C}$, es dada por:

$$
\mathcal{C} = \{(x - c)_{+}, (c - x)_{+}\} \quad \text{con} \quad c \in \{x_{1i}, x_{2i}, \ldots, x_{ni}\} \quad \text{y} \quad i = 1, \ldots, p
$$

Cada función es lineal a trozos con un nudo ('knot') $c$ en cada $x_{ij}$, y si todos los valores de entrada son distintos, hay $np$ funciones de bisagra o, de manera equivalente, $2np$ funciones básicas. Usando estas BF, la estrategia de construcción del modelo es similar a una regresión paso a paso hacia adelante clásica, que utiliza las funciones del conjunto $\mathcal{C}$ y sus productos como entradas. La expresión final del modelo es:

$$
Y = \beta_0 + \sum_{m=1}^{M} \beta_m h_m(X) + \epsilon
$$

\noindent donde $h_m(X)$ es una BF o un producto de dos o más tales funciones, si se permiten interacciones entre variables, o quizás el predictor original, si tiene un impacto lineal en la variable dependiente. Los coeficientes $\beta_m$ se estiman minimizando la suma del cuadrado de los errores (SCE), similar a un modelo de regresión lineal estándar.


### El Paso Hacia Adelante

El proceso de entrenamiento del modelo selecciona y añade de manera iterativa algunas funciones bisagra al modelo (o al predictor original). Durante cada paso del proceso de entrenamiento, MARS selecciona nuevos términos que minimizan la suma de los cuadrados de los errores (SCE) utilizando los mínimos cuadrados ordinarios (OLS). En este paso hacia adelante, el algoritmo MARS comienza con un modelo que solo incluye el término de intersección $\beta_0$. En cada paso subsiguiente, se selecciona y añade al modelo un par reflejado de funciones bisagra y un predictor original. Este par puede entrar directamente al modelo o, alternativamente, multiplicarse por una función básica (BF) ya existente en el modelo, convirtiéndose en nuevas BFs. Este segundo caso permite modelar la interacción entre los diferentes predictores.

El proceso de paso hacia adelante continúa hasta que se cumple una de varias condiciones que pueden ser impuestas a priori, como: (i) alcanzar el número máximo de términos del modelo (elegido por el usuario) antes de la poda, o (ii) cuando añadir un término cambia ($R^2$) a un valor inferior al umbral seleccionado por el usuario (por ejemplo, 0,001). La búsqueda de funciones bisagra en cada paso puede realizarse mediante fuerza bruta, pero este proceso puede acelerarse utilizando una heurística que reduce el número de términos parentales a considerar @friedman1991.

En general, al final de este proceso, obtenemos un modelo grande en la forma descrita en la ecuación (1). El modelo MARS obtenido en este paso hacia adelante es adaptable y puede mostrar un alto grado de flexibilidad, lo que puede resultar en sobreajuste si no se toman medidas correctivas. Para resolver el problema del sobreajuste y construir un modelo con mejor capacidad de generalización, se debe aplicar un procedimiento de poda.

### El Proceso de Poda

Aunque existen otros métodos, MARS típicamente aplica un procedimiento de eliminación hacia atrás para podar el modelo. Así, en la segunda fase del algoritmo MARS, se aplica un procedimiento de eliminación "uno a la vez" en el cual se elimina repetidamente la función básica que tiene la menor contribución al modelo. Esta poda se basa en el criterio de validación cruzada generalizada (GCV), propuesto originalmente por @craven1978smoothing} y adaptado por @friedman1989}. La expresión del GCV es:

$$
GCV = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y_i})^2 \left( 1 - \frac{\hat{C}(M)}{n} \right)^2
$$

\noindent donde $\hat{y_i}$ son los valores ajustados y $\hat{C}(M) = C(M) + dK$, siendo $C(M)$ el número de parámetros que se están estimando (el número de funciones básicas linealmente independientes sin el término de intersección); $K$ es el número de nudos seleccionados en el proceso hacia adelante, y  $d$ representa el costo de cada optimización de función básica. Generalmente, $d = 2$ si el modelo no involucra términos de interacción, y $d = 3$ en caso contrario @friedman1991}. Por lo tanto, la fórmula del $GCV$ ajusta el SCE para tener en cuenta la flexibilidad del modelo. Valores más grandes de $d$ resultan en menos nudos y estimaciones de funciones más suaves. La mejor aproximación de MARS es aquella con el valor más bajo de $GCV$. Para obtener una medida similar a $ R^2 $, se puede estandarizar el coeficiente GCV y definir un nuevo coeficiente como:

$$
GRSq = 1 - \frac{GCV}{GCV_{tot}}
$$

\noindent donde $GCV_{tot}$ es el $GCV$ de un modelo que solo contiene el término de intersección.

Es importante notar que el $SCE$ bruto es inadecuado para comparar modelos, ya que el $SCE$ siempre aumenta al eliminar términos de MARS; por ende, la aplicación de este criterio en el paso hacia atrás siempre resulta en seleccionar el modelo más grande. Por lo tanto, el criterio $GCV$ se utiliza para encontrar el mejor modelo general a partir de una secuencia de modelos ajustados. El paso hacia atrás comienza con el modelo completo devuelto por el paso hacia adelante. Luego, en cada paso, se elimina el término que resulta en el submodelo con el SCE más bajo. Este proceso iterativo continúa hasta alcanzar el modelo que solo tiene el término de intersección. Finalmente, el paso hacia atrás selecciona el modelo final: el submodelo con el $GCV$ más bajo.

### Hyperparámetros del Algoritmo MARS

Existen varios parámetros de ajuste asociados con el algoritmo MARS que los investigadores pueden seleccionar. Citamos aqui algunos de los mas importantes.
\begin{itemize}
    \item \textit{Umbral para la terminación del paso hacia adelante}: se establece un criterio para determinar cuándo debe finalizar el proceso de selección.
    \item \textit{Número mínimo de observaciones entre nodos}: se especifica cuántas observaciones son necesarias antes de considerar la creación de un nuevo nodo.
    \item \textit{Selección de variables}: se decide qué variables se incluirán en su forma lineal
    \item \textit{ Orden de interacción entre variables}: se define cuántas interacciones se permiten entre las variables.
    \item \textit{Número máximo o mínimo de nodos}: se limita cuántos nodos pueden formarse durante el proceso.
\end{itemize}
Esta lista no es exhaustiva y se puede encontrar más información sobre estos parámetros en el trabajo de @friedman1991. 

 

### AUC. Medida para evaluar los modelos

El AUC (Área Bajo la Curva) es un indicador de calidad para modelos logit que mide su capacidad discriminativa. Representa el área bajo la curva ROC, que evalúa la relación entre sensibilidad y especificidad. Un AUC cercano a 1 indica excelente desempeño, mientras que valores próximos a 0.5 reflejan un modelo aleatorio.

# Resultados

Se aplicó el algoritmo MARS al conjunto de datos con la librería earth del software libre R [@earth]. Se aplicó un procedimiento de ajuste de hiperparámetros del algoritmo, que combinó un ejercicio de validación cruzada k-fold con una búsqueda en malla (grid search) con el objetivo de maximizar el AUC. El ejercicio de validación cruzada con k=5-folks se utilizó para identificar el número máximo de términos, optiendo los mejores resultados limitando a 25 el número de términos en el modelo. Fijando el número máximo de términos en 25 se realizó una búsqueda de hiperpárametros (minspan=número mínimo de observaciones entre knots y número máximo de interacciones entre variables) para calibrar la capacidad predictiva del modelo seleccionando una submuestra de entrenamiento del 70% y una de test del 30%. Este proceso de búsqueda determinó un valor minspan=3000 y 2 términos máx de interacción. El modelo MARS-logit óptimo selecciona 22 términos de interacción entre variables y utiliza 9 predictores para analizar el abandono universitario. El AUC del modelo final resultó ser AUC-MARS=0,72.

Otros dos algoritmos se aplicaron a esta base de datos, un modelo logit y el algortitmo Random Forest. El modelo logir logró un AUC-Logit=0.70, levemente inferior al AUC-MARS. De forma paralela se lanzó en algoritmo de Random Forest con el paquete de R ranger [@ranger] al que igualmente se le aplicó una búsqueda de hiperparámetros para determinar el número óptimo de predictores. Los mejores resultados se obtuvieron con 5 predictores. En este caso el AUC-RF=0,75 fue levemente superior al que se obtuvo con MARS 

La Tabla \ref{tab:MARS-logit} muestra los resultados del modelo MARS-logit. En primer el algoritmo no considera relevantes, ni para incluirlas linealmente ni tampoco ninguna de las BF, las variables "Universidad"; NotaMinima"; "EdadMedia"; "MadreUniv"; "PAsoc"; "PAyuDoc". En segundo lugar el algoritmo seleccionó variables dicotómicas *Género*, *Adscrito* junto con *RamaIA*. Los resultados indican que el género (*Mujer* ser mujer), la rama de conocimiento en la que el estudiante se matricula (solo es relevante IA Ingeniería y Arquitectura) junto con el hecho de realizar los estudios en un centro adscrito (*Adscrito*) son factores relevantes. Mientras que ser mujer y estar matriculado en un centro adscrito disminuyen la probabilidad de abandono, el realizar los estudios en la rama de IA incrementa notablemente.

En tercer lugar el algoritmo MARS ha seleccionado algunas funciones básicas (BF) que tienen un impacto no lineal. Las variables, *nacceso*, *provincia*, *NotaMediana* y *PadreUniv* se incluyen en este grupo. El algoritmo divide la nota (mediana) el punto de corte en 8,1 de tal forma que un estudiante que entra en una titulación con nota superior a 8,1 disminuye la probabilidad $(NotaMediana-8,1)_+$ y con nota inferior $(8,1-NotaMediana)_+$ incrementa la probabilida de pertenecer al grupo de "abandono". Una BF es seleccionada de *nacceso* $(nacceso-515)_+$ de tal forma que iniciar estudios en titulaciones donde acceden muchos estudiantes (>515 como media anual) incrementa la probabilidad de abandono. Solo una función básica en incluida en el modelo $(n.acceso-515)_+$ y aparece con signo positivo, indicando que cuando el número de alumnos es inferior 515 el algoritmo no lo considera relevante y no es incluido en la modelización. @delogu2024 también identifica que esta variable es relevante cuando analiza el abandono en el caso italiano. El porcentaje de estudiantes en una titulación superior al 82% disminuye la probabilidad mientras que si el porcentaje es superior al 82% incrementa la probabilidad. Los estudiantes que están matriculados en titulaciones donde el % de padres con estudios universitarios es mayor que 0.28 incrementa la probabilidad de fracaso.


En tercer lugar varias interacciones entre dos variables mejoran el modelo. La interacción entre *Mujer* y *NotaMediana* es relavante de tal forma que si es muje y está en una titualción con nota mediana superior a 10.9 increment la ....los anteriores resultados son matizados por la incorporación de interacciones entre variables

Una cuestión relevante que se obtiene del algoritmo es la influencia de la geografía sobre la variable TR04. El porcentaje de estudiantes que en la titulación pertenecen a la misma provincia y al mismo municipio aparecen interactuando con otras variables. También @yu2010 identifica la residencia como un predictor crucial para la retención.

**La interacción entre Provincia y nacceso es relevante. Altos porcentajes (>0,72) de estudiantes de la provincia en titulaciones con nacceso <515 reduce la probabilidad de abandono. $(515-nacceso)_+·(Provincia-0,72)_+$**

<!-- **** -->

<!-- @constante2021 TAMBIEN CONSIDERA EL % DE  -->
<!-- Respecto a la edad, el signo positivo de su coeficiente indica que los estudiantes que tienen 20 años o más tienen menos probabilidad de permanecer en la enseñanza superior -->

<!-- El signo negativo estimado para la variable nota de acceso, significa -->
<!-- que, por cada punto más en la nota de acceso, la odds de abandonar disminuye -->
<!-- un 22%.  -->

<!-- En relación con el área de conocimiento, se puede apreciar que el -->
<!-- alumnado que pertenece a las áreas de Ciencias Sociales y Jurídicas y Artes -->
<!-- y Humanidades tienen un 43% menos de probabilidad de abandonar.  -->

<!-- Los -->
<!-- hombres tienen un 42% más de probabilidades de abandonar que las mujeres. -->
<!-- Respecto al lugar de nacimiento se puede apreciar que los estudiantes que han -->
<!-- nacido fuera de España tienen un 38% más de probabilidad de abandonar -->
<!-- que los estudiantes autóctonos -->

<!-- **** -->


```{=tex}
\begin{table}[ht!]
\label{tab:MARS-logit}
\centering
\caption{Resultados del modelo MARS-logit}
\begin{tabular}{lrr}
\hline
\textbf{Variable} & \textbf{Coeficiente} & \textbf{OR} \\
\hline
Constante                                 & -1.681   & 0.186   \\
Género (Mujer)                       & -0.424   & 0.655   \\
Rama (Ingeniería y Arquitectura)    &  0.986   & 2.681   \\
Adscrito                             & -0.591   & 0.554   \\
$(8.1-NotaMediana)_+$                 & -0.316   & 0.729   \\
$(NotaMediana-8.1)_+$                 & -0.331   & 0.718   \\
$(0.82 - Provincia)_+$                  &  3.262   & 26.121  \\
$(Provincia - 0.82)_+$                  & -14.299  & 6.2e-07 \\
$(nacceso - 515)_+$                     &  0.001   & 1.001   \\
$(PadreUniv-0.28)_+$                   &  1.691   & 5.420   \\
Mujer·$(NotaMediana-10.9)_+$    &  0.077   & 1.08    \\
Mujer·$(10.9-NotaMediana)_+$    & -0.091   & 0.91    \\
Doble·$(515-nacceso)_+$                  & -0.002   & 0.998   \\
RamaIA·$(NotaMediana - 8.8)_+$          & -0.211   & 0.81    \\
$(12 - nacceso)_+$·$(0.82 - Provincia)_+$     &  0.587   & 1.80    \\
$(nacceso - 12)_+$·$(0.82 - Provincia)_+$     & -0.008   & 0.992   \\
$(0.32 - Municipio)_+$·$(0.82-Provincia)_+$ & -6.690   & 0.0012  \\
$(Municipio - 0.32)_+$·$(0.82 -Provincia)_+$ & 33.857   & 5.1e14  \\
$(515-nacceso)_+$·$(Provincia-0.72)_+$    &  0.020   & 1.02    \\
$(515-nacceso)_+$·$(0.72-Provincia)_+$    & -0.004   & 0.996   \\
\hline
\multicolumn{3}{l}{Earth selected 22 of 23 terms, and 9 of 22 predictors (nprune=25)} \\
\multicolumn{3}{l}{AIC = 134400} \\
\multicolumn{3}{l}{AUC = 0,72} \\
\multicolumn{3}{l}{GCV=0.097; RSS=19693.02; GRSq=0.077; RSq=0.077} \\ 
\hline
\end{tabular}
\end{table}
```

## La importancia de las variables

La Figura \ref{fig:importancia} muestra la importancia relativa de las variables obtenida mediante dos algoritmos de aprendizaje: MARS y Random Forest. En el eje horizontal se enumeran las variables analizadas, mientras que el eje vertical muestra su peso en el modelo predictivo, medido en función de su contribución a la precisión. Cada barra representa la importancia asignada por cada algoritmo, diferenciada por colores. La comparación destaca cómo cada método prioriza distintos factores según su enfoque: MARS se centra en relaciones lineales y no lineales ajustadas, mientras que Random Forest evalúa interacciones complejas y jerarquías entre variables.

El gráfico muestra la importancia relativa de las variables según los algoritmos MARS (izquierda) y Random Forest (derecha). En ambos casos, las variables **"Rama"** y **"nota.mediana"** son las más relevantes, lo que indica su peso significativo en los modelos predictivos. En el caso de MARS, la distribución de las importancias es más uniforme, mientras que Random Forest asigna una mayor diferenciación entre las variables, destacando también **"n.acceso"** y **"edad.media.tit"**. Variables como **"muni.local"** y **"prov.local"** tienen un impacto moderado en ambos enfoques. Random Forest ofrece un mayor contraste en las variables menos influyentes, evidenciando diferencias metodológicas entre ambos algoritmos.

```{r importancia MARS, cache=TRUE,echo=FALSE}
mymars.imp <- earth::evimp(mymars,trim = TRUE)
evdf = as.data.frame(unclass(mymars.imp[,c(3,4,6)]))
rownames(evdf)[3] <- "Mujer"
rownames(evdf)[8] <- "Adscrito"
rownames(evdf)[7] <- "Doble"
p1.imp <- ggplot(data = evdf,
  aes(x    = reorder(rownames(evdf), evdf$gcv),
      y    = evdf$gcv, fill = evdf$gcv)) +
labs(x = "",y="", title = "") +
geom_col() +
coord_flip() +
theme_bw() +
theme(legend.position = "none")
```


```{r RF, warning=FALSE,message=FALSE,echo=FALSE,cache=TRUE}
library(ranger)
modelo_0  <- ranger(
            formula   = formula,
            data      = bd,
            num.trees = 500,
            probability = TRUE,
            mtry = 5,
            max.depth = 30,
            importance = "impurity",
            seed = 123)
```


```{r importancia RF, warning=FALSE,message=FALSE, echo=FALSE,fig.height=3,  fig.cap="\\label{fig:importancia} Importancia normalizada de las variables. A la izquierda aplicando el algoritmo MARS a la derecha con el algoritmo Random Forest. Las variables no utilizadas no aparecen en el gráfico"}
modelo_0$variable.importance <- 100*modelo_0$variable.importance/max(modelo_0$variable.importance)
importancia <- modelo_0$variable.importance %>%
    enframe(name = "predictor", value = "importancia")

importancia <- importancia[order(importancia$importancia),]
importancia <- as.data.frame(importancia)
importancia$predictor[12]<-"EdadMedia"
p2.imp <- ggplot(data = importancia,
  aes(x    = reorder(predictor, importancia),
      y    = importancia, fill = importancia)) +
labs(x = "",y="",title = "") +
geom_col() +
coord_flip() +
theme_bw() +
theme(legend.position = "none")
ggarrange(p1.imp, p2.imp,ncol=2, nrow=1,common.legend = F)
```


```{r ROC, echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE, fig.height=3.5, fig.width=5, fig.cap="\\label{fig:roc} asdads"}
predicciones.mymars <- predict(mymars, type = "response")
predicciones.mylogit <- predict(mylogit, type = "response")
predicciones.rf <- predict(modelo_0, data = bd)
auc.rf <- round(auc(bd$abandono, predicciones.rf$predictions[,2]),4)
auc.mars <- round(auc(bd$abandono, predicciones.mymars),4)
auc.logit <- round(auc(bd$abandono, predicciones.mylogit),4)
rocobj.rf <- roc(bd$abandono, predicciones.rf$predictions[,2])
rocobj.mars <- roc(bd$abandono, predicciones.mymars)
rocobj.logit <- roc(bd$abandono, predicciones.mylogit)
ggroc(list(RF = rocobj.rf, 
           MARS = rocobj.mars,
           Logit = rocobj.logit), size=.5) +
  labs(x = "1-Specificity", y = "Sensitivity") + 
  geom_abline(intercept = 1, slope = 1, color='grey',size = 0.5,linetype = "dashed") + 
    scale_y_continuous(expand = c(0.01, 0.001),breaks= seq(from = 0 , to = 1 ,by = 0.2))+
  scale_x_reverse(expand = c(0.01, 0.001),breaks= seq(from = 0 , to = 1 ,by = 0.2),limits = c(1,-0.01),labels = c("1.0","0.8","0.6","0.4","0.2","0.0")) +
  theme_bw()
```


# Conclusiones

tururu

El abandono universitario tiene efectos adversos en distintos niveles. A nivel social, implica una pérdida de capital humano que puede limitar el desarrollo económico. Además, supone un desperdicio de recursos públicos invertidos en educación. A nivel individual, se traduce en menores oportunidades laborales y salariales para aquellos estudiantes que abandonan sus estudios y también incrementa para sus familias que ven un proyecto arruinado [@aina2022]. @aina2022 también presenta un resumen en la Tabla 2 sobre los efectos estimados de los predictores del abandono universitario según la evidencia empírica.

## Propuestas para remediar el abandono

<!-- La formación remedia no solo se encarga de la mejora de las destrezas académicas, sino que también debe incluir servicios de orientación, asesoramiento, tutorías y talleres, entre otros. Esto ayuda a todos los estudiantes, no solo a aquellos que carecen de competencias al momento de ingresar a la educación superior (@bahr2007; @bahr2008a; @bahr2008b). -->

Dado el alto índice de abandono en las universidades, muchas instituciones han adoptado diversas estrategias y programas de prevención del abandono. Este tema ha sido objeto de estudio durante las últimas dos décadas, y se han propuesto numerosos planes y programas.
<!-- [@huntington2020]. -->
Muchos de estos programas se desarrollan para anticiparse a las causas clave del abandono estudiantil y a la asistencia irregular. La literatura destaca la importancia de abordar estos problemas antes del inicio del curso académico o en las primeras etapas de la educación superior. Las pruebas de diagnóstico temprano han demostrado ser altamente efectivas, reduciendo significativamente las tasas de abandono estudiantil.

Además, @cholewa2015 sugiere que la personalización de la educación, junto con la orientación personalizada, puede aumentar las posibilidades de éxito académico. Por otro lado, @terry2008 subraya la importancia del apoyo familiar en la toma de decisiones de los estudiantes. Una participación activa de los padres puede ser un factor determinante en la retención, mientras que su ausencia aumenta la propensión al abandono.


Existen grandes programas de prevención del abandono, pero nos centraremos en el desarrollado por la Comunidad Europea. Se ha presentado una propuesta titulada **Marco Europeo para Cursos Preparatorios de Transición Secundaria-Universidad**, que incluye diversos programas, destacando el “Lifelong Learning Programme”. Este programa ofrece una base de datos que, desde 2009, ha proporcionado 118 cursos que reflejan lo que ocurre con la formación remedial en Europa.

En el caso de España, las universidades cuentan con diferentes Planes de Acción Tutorial (PAT), que orientan a los estudiantes sobre la disponibilidad y el uso de recursos para el aprendizaje, así como orientaciones académicas y profesionales, entre otras directrices [@romera2020]. Un ejemplo destacado es el PAT de la Universidad de León, vigente desde 2002, que incluye procesos de acogida, información y orientación dirigidos a los estudiantes de nuevo ingreso, facilitando así su incorporación a una vida universitaria plena (@medialdea2014). @alonso2024 demuestra que los programas de mentoría implementados en las universidades españolas son efectivos para reducir el abandono universitario y mejorar el rendimiento académico. Este enfoque no solo permite caracterizar el fenómeno, sino también ofrecer recomendaciones prácticas basadas en evidencia para reducir las tasas de abandono.




# Referencias